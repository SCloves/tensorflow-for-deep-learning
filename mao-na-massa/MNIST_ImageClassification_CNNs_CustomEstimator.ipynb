{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('mnist_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(digit):\n",
    "    plt.imshow(digit.reshape(28, 28), cmap='Greys',interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf04038e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(mnist.train.images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_featrure_maps = 32\n",
    "conv1_kernel_size = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = 'SAME'\n",
    "\n",
    "conv2_featrure_maps = 64\n",
    "conv2_kernel_size = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = 'SAME'\n",
    "\n",
    "pool3_feature_maps = conv2_featrure_maps\n",
    "\n",
    "n_fullyconn1 = 64\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(features):\n",
    "    X = tf.reshape(features['images'], shape=[-1, height, width, channels])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(X, filters=conv1_featrure_maps,\n",
    "                            kernel_size=conv1_kernel_size,\n",
    "                            strides=conv1_stride, padding=conv1_pad,\n",
    "                            activation=tf.nn.relu)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(conv1, filters=conv2_featrure_maps,\n",
    "                            kernel_size=conv2_kernel_size, \n",
    "                            strides=conv2_stride, padding=conv2_pad,\n",
    "                            activation=tf.nn.relu)\n",
    "    \n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='VALID')\n",
    "    \n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_feature_maps * 7 * 7])\n",
    "    \n",
    "    fullyconn1 = tf.layers.dense(pool3_flat, n_fullyconn1,\n",
    "                                activation=tf.nn.relu)\n",
    "    \n",
    "    logits = tf.layers.dense(fullyconn1, n_outputs)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    logits = build_cnn(features)\n",
    "    predicted_classes = tf.argmax(logits, axis=1)\n",
    "    \n",
    "    # prediction mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predicted_classes)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # training mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Evaluation mode\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predicted_classes)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predicted_classes,\n",
    "        train_op=train_op,\n",
    "        loss=loss,\n",
    "        eval_metric_ops={'accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 2000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp0fxn2wtb\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp0fxn2wtb', '_num_ps_replicas': 0, '_master': '', '_is_chief': True, '_task_type': 'worker', '_session_config': None, '_service': None, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_num_worker_replicas': 1, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdf03f7bf98>, '_task_id': 0}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(cnn_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {'images': mnist.train.images}, y = mnist.train.labels,\n",
    "        batch_size=batch_size, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c1b2fd7c02c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 743\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    744\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5ee67df394a5>\u001b[0m in \u001b[0;36mcnn_model_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m---> 10\u001b[0;31m             logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[1;32m   1959\u001b[0m                        \u001b[0;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2)."
     ]
    }
   ],
   "source": [
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
